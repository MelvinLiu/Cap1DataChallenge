{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84a35e3-b6eb-4213-9902-a26f6ae8d3a5",
   "metadata": {},
   "source": [
    "## 00 - Data Prprepation\n",
    "### <strong>Objective: </strong>\n",
    "<p>The objective of this notebook is to import, restructure and clean flights (Flight.csv), tickets (Tickets.csv), and airport data (Airport_Codes.csv) data before analysis. </p>\n",
    "\n",
    "### <strong>Methodology: </strong>\n",
    "<p>\n",
    "    1. Read in provided CSV files (Flight.csv, Tickets.csv and Airport_Codes.csv);<br>\n",
    "    2. Data Wrangling, Validation and Cleaning <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 2.1. Trim data based on business criteria (e.g. round trips only and medium and large airpots only); <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 2.2. Check null values and judgementally treat them (e.g. substitute with zeros or drop respective rows); <br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 2.3. Assess the data types in each column and reassign them to the appropriate data types if they are incorrect (e.g., converting from 'Object' to 'DateTime' for date values).<br>\n",
    "    3. Save cleaned data to CSV files (cleaned_Flight.csv, cleaned_Tickets.csv and cleaned_Airport_Codes.csv) for next steps;<br>\n",
    "\n",
    "<strong> Please note that we deliberately chose not to identify and remove any outliers in the data preparation step, as our priority is to perserve the completeness of the raw data before conducting any analysis. Subsequently, we will perform additional analysis in <i> 01_airline_core_analysis </i> to identify data distributions and outliers. </strong>\n",
    "</p>\n",
    "\n",
    "### <strong>Results: </strong>\n",
    "<p>Results will have three new CSV files (cleaned_Flight.csv, cleaned_Tickets.csv and cleaned_Airport_Codes.csv) </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8ddd4-0895-4511-8d88-dea1c9bd3a70",
   "metadata": {},
   "source": [
    "#### <strong>Import libraries and helper functions</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c1b991-eb65-4062-84f0-a173c7db9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helper_type_converter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fedca-f9fb-4f5c-99a9-aee219b723ba",
   "metadata": {},
   "source": [
    "#### <strong>1. Read in Raw Data</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41851275-e63c-4bce-b954-fa9b257c39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26486/1754582172.py:1: DtypeWarning: Columns (3,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_flights = pd.read_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_raw/Flights.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "df_flights = pd.read_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_raw/Flights.csv')\n",
    "df_tickets = pd.read_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_raw/Tickets.csv')\n",
    "df_airport_codes = pd.read_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_raw/Airport_Codes.csv')\n",
    "\n",
    "print(\"Imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dccce9-5634-4ad4-8bc2-9a6e0d8f9c79",
   "metadata": {},
   "source": [
    "#### <strong>2.Data Wrangling, Validation and Cleaning (Flight.csv)</strong>\n",
    "<p>\n",
    "    For flights, we do not need to consider any cancelled flights. Hence, we remove them from dataframe.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a3fcd1-9dc0-4877-8d6a-1077e93c871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Flights =  1915886\n",
      "Total Number of Flights (removed cancelled =  1864272\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Flights = \", len(df_flights))\n",
    "\n",
    "df_flights_removed_cancelled = df_flights[df_flights['CANCELLED'] == 0]\n",
    "print(\"Total Number of Flights (removed cancelled = \", len(df_flights_removed_cancelled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bfa0b-33bc-48df-8b29-44bca7aeb82b",
   "metadata": {},
   "source": [
    "<p>\n",
    "For flights, we first check if there are any null values in the dataframe. It turned out that we found a couple of them in ARR_DELAY, AIR_TIME, DISTANCE, and OCCUPANCY_RATE. <br>\n",
    "We judiciously filled all ARR_DELAY with zero, assuming there was no delay. Then, we dropped any rows with null values, as estimating AIR_TIME, DISTANCE, and OCCUPANCY_RATE without complete information is challenging.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25db303-839d-4967-8399-5df70305028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FL_DATE                 0\n",
       "OP_CARRIER              0\n",
       "TAIL_NUM                0\n",
       "OP_CARRIER_FL_NUM       0\n",
       "ORIGIN_AIRPORT_ID       0\n",
       "ORIGIN                  0\n",
       "ORIGIN_CITY_NAME        0\n",
       "DEST_AIRPORT_ID         0\n",
       "DESTINATION             0\n",
       "DEST_CITY_NAME          0\n",
       "DEP_DELAY               0\n",
       "ARR_DELAY            4377\n",
       "CANCELLED               0\n",
       "AIR_TIME             5027\n",
       "DISTANCE              610\n",
       "OCCUPANCY_RATE        310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights_removed_cancelled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429d1318-e688-45f3-9685-8cc15d1cb268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26486/1842833538.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_flights_removed_cancelled['ARR_DELAY'] = df_flights_removed_cancelled['ARR_DELAY'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "#fill null with 0, if reasonable\n",
    "df_flights_removed_cancelled['ARR_DELAY'] = df_flights_removed_cancelled['ARR_DELAY'].fillna(0)\n",
    "\n",
    "#drop rows with null\n",
    "df_flights_cleaned = df_flights_removed_cancelled.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a1330-f65a-4f30-8c9e-c2e19e889b51",
   "metadata": {},
   "source": [
    "<p>\n",
    "By assessing the data types, we realized that a few columns have incorrect data types, and FL_DATE contains mixed date formats. Therefore, we utilized our helper function to convert the data types to the correct ones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ae12da-fa5b-4abd-aef0-028ffa35044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchengliu/Desktop/c1 data challenge/helper_type_converter.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df[input_column] = pd.to_datetime(input_df[input_column], format = 'mixed')\n",
      "/Users/yuchengliu/Desktop/c1 data challenge/helper_type_converter.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df[input_column] = pd.to_numeric(input_df[input_column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1858595 entries, 0 to 1915885\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   FL_DATE            datetime64[ns]\n",
      " 1   OP_CARRIER         object        \n",
      " 2   TAIL_NUM           object        \n",
      " 3   OP_CARRIER_FL_NUM  object        \n",
      " 4   ORIGIN_AIRPORT_ID  int64         \n",
      " 5   ORIGIN             object        \n",
      " 6   ORIGIN_CITY_NAME   object        \n",
      " 7   DEST_AIRPORT_ID    int64         \n",
      " 8   DESTINATION        object        \n",
      " 9   DEST_CITY_NAME     object        \n",
      " 10  DEP_DELAY          float64       \n",
      " 11  ARR_DELAY          float64       \n",
      " 12  CANCELLED          float64       \n",
      " 13  AIR_TIME           float64       \n",
      " 14  DISTANCE           float64       \n",
      " 15  OCCUPANCY_RATE     float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(7)\n",
      "memory usage: 241.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#convert data types to correct ones\n",
    "convert_to_datetime(df_flights_cleaned, 'FL_DATE')\n",
    "convert_to_num(df_flights_cleaned, 'AIR_TIME')\n",
    "convert_to_num(df_flights_cleaned, 'DISTANCE')\n",
    "\n",
    "df_flights_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677976aa-96d1-442e-99df-5e81b650d352",
   "metadata": {},
   "source": [
    "#### <strong>2.Data Wrangling, Validation and Cleaning (Tickets.csv)</strong>\n",
    "<p>\n",
    "    For tickets, we only need to consider round trips. Hence, we filter out any tickets that were not round trip.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc907c4-ccc7-4633-b045-535e1290737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets_round_only = df_tickets[df_tickets['ROUNDTRIP'] == 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97beb3-a5b9-4c04-98da-4aa981d22009",
   "metadata": {},
   "source": [
    "<p>\n",
    "For tickets, we first check if there are any null values in the dataframe. It turned out that we found a couple of them in PASSENGERS, and ITIN_FARE. Given that both columns are harder to estimate, we dropped any rows with null values.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5593e5-1b65-4bd0-8227-8f5bb8bd86d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITIN_ID                 0\n",
      "YEAR                    0\n",
      "QUARTER                 0\n",
      "ORIGIN                  0\n",
      "ORIGIN_COUNTRY          0\n",
      "ORIGIN_STATE_ABR        0\n",
      "ORIGIN_STATE_NM         0\n",
      "ROUNDTRIP               0\n",
      "REPORTING_CARRIER       0\n",
      "PASSENGERS           1197\n",
      "ITIN_FARE             560\n",
      "DESTINATION             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_tickets_round_only.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c81b84-54ae-40eb-94af-2548c0b724ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets_cleaned = df_tickets_round_only.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096bee0f-cb1f-4625-a3cf-10085f52d057",
   "metadata": {},
   "source": [
    "<p>\n",
    "By assessing the data types, we realized that the ITIN_FARE columns has incorrect data types. Hence, we utilized our helper function to convert the data types to the correct ones.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba00fc6e-b4ad-44b9-b117-a25645d1fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 706849 entries, 0 to 1167284\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ITIN_ID            706849 non-null  int64  \n",
      " 1   YEAR               706849 non-null  int64  \n",
      " 2   QUARTER            706849 non-null  int64  \n",
      " 3   ORIGIN             706849 non-null  object \n",
      " 4   ORIGIN_COUNTRY     706849 non-null  object \n",
      " 5   ORIGIN_STATE_ABR   706849 non-null  object \n",
      " 6   ORIGIN_STATE_NM    706849 non-null  object \n",
      " 7   ROUNDTRIP          706849 non-null  float64\n",
      " 8   REPORTING_CARRIER  706849 non-null  object \n",
      " 9   PASSENGERS         706849 non-null  float64\n",
      " 10  ITIN_FARE          705561 non-null  float64\n",
      " 11  DESTINATION        706849 non-null  object \n",
      "dtypes: float64(3), int64(3), object(6)\n",
      "memory usage: 70.1+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchengliu/Desktop/c1 data challenge/helper_type_converter.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df[input_column] = pd.to_numeric(input_df[input_column], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "convert_to_num(df_tickets_cleaned, 'ITIN_FARE')\n",
    "df_tickets_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed72b59-dd0f-4bbd-ae5c-03c815ff450c",
   "metadata": {},
   "source": [
    "#### <strong>2.Data Wrangling, Validation and Cleaning (Airport_Codes.csv)</strong>\n",
    "<p>\n",
    "    For airports, we only need to consider large and medium airports in the US. Hence, we filter out any airports that do not fill into these three categories (Must be medium or large airpot in the US).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ada1de-c102-47ea-9009-1f5673cffe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport_large_medium_only = df_airport_codes[ (df_airport_codes['TYPE'] == 'medium_airport') | (df_airport_codes['TYPE'] == 'large_airport')]\n",
    "df_airport_large_medium_only = df_airport_large_medium_only[ (df_airport_large_medium_only['ISO_COUNTRY'] == 'US')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17056ba8-b75c-409d-bc6f-8a7c3f161192",
   "metadata": {},
   "source": [
    "<p>\n",
    "For airports, we check if there are any null values in the dataframe. It turned out that we found a couple of them in ELEVATION_FT, CONTINENT, MUNICIPALITY, and IATA_CODE. We decided to drop CONTINENT and ISO_COUNTRY as we already filtered out any non-US airport and continent does not provide too much valuable information for us. <br>\n",
    "After dropping the two columns, we dropped any rows with null values as they are harder to estimate, \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "795b85df-c895-462f-97d4-d8b0635644e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TYPE              0\n",
       "NAME              0\n",
       "ELEVATION_FT      3\n",
       "CONTINENT       858\n",
       "ISO_COUNTRY       0\n",
       "MUNICIPALITY      3\n",
       "IATA_CODE        37\n",
       "COORDINATES       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_large_medium_only.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c0f1e3-9756-428a-984f-2cd18ef18c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ELEVATION_FT</th>\n",
       "      <th>MUNICIPALITY</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>COORDINATES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Aleknagik / New Airport</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Aleknagik</td>\n",
       "      <td>WKK</td>\n",
       "      <td>-158.617996216, 59.2826004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26143</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Lehigh Valley International Airport</td>\n",
       "      <td>393.0</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>ABE</td>\n",
       "      <td>-75.44080352783203, 40.652099609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26144</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Abilene Regional Airport</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>ABI</td>\n",
       "      <td>-99.68190002440001, 32.4113006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26145</th>\n",
       "      <td>large_airport</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>5355.0</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>-106.609001, 35.040199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26146</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Aberdeen Regional Airport</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>ABR</td>\n",
       "      <td>-98.42179870605469, 45.449100494384766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38972</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Kahului Airport</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Kahului</td>\n",
       "      <td>OGG</td>\n",
       "      <td>-156.429993, 20.8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38974</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Bradshaw Army Airfield</td>\n",
       "      <td>6190.0</td>\n",
       "      <td>Camp Pohakuloa</td>\n",
       "      <td>BSF</td>\n",
       "      <td>-155.554000854, 19.760099411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38975</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Hilo International Airport</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>ITO</td>\n",
       "      <td>-155.04800415039062, 19.721399307250977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38976</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Upolu Airport</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Hawi</td>\n",
       "      <td>UPP</td>\n",
       "      <td>-155.86000061035156, 20.265300750732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39286</th>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Point Lay LRRS Airport</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Point Lay</td>\n",
       "      <td>PIZ</td>\n",
       "      <td>-163.0050049, 69.73290253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TYPE                                 NAME  ELEVATION_FT  \\\n",
       "6194   medium_airport              Aleknagik / New Airport          66.0   \n",
       "26143  medium_airport  Lehigh Valley International Airport         393.0   \n",
       "26144  medium_airport             Abilene Regional Airport        1791.0   \n",
       "26145   large_airport    Albuquerque International Sunport        5355.0   \n",
       "26146  medium_airport            Aberdeen Regional Airport        1302.0   \n",
       "...               ...                                  ...           ...   \n",
       "38972  medium_airport                      Kahului Airport          54.0   \n",
       "38974  medium_airport               Bradshaw Army Airfield        6190.0   \n",
       "38975  medium_airport           Hilo International Airport          38.0   \n",
       "38976  medium_airport                        Upolu Airport          96.0   \n",
       "39286  medium_airport               Point Lay LRRS Airport          22.0   \n",
       "\n",
       "         MUNICIPALITY IATA_CODE                              COORDINATES  \n",
       "6194        Aleknagik       WKK            -158.617996216, 59.2826004028  \n",
       "26143       Allentown       ABE      -75.44080352783203, 40.652099609375  \n",
       "26144         Abilene       ABI        -99.68190002440001, 32.4113006592  \n",
       "26145     Albuquerque       ABQ                   -106.609001, 35.040199  \n",
       "26146        Aberdeen       ABR   -98.42179870605469, 45.449100494384766  \n",
       "...               ...       ...                                      ...  \n",
       "38972         Kahului       OGG                     -156.429993, 20.8986  \n",
       "38974  Camp Pohakuloa       BSF             -155.554000854, 19.760099411  \n",
       "38975            Hilo       ITO  -155.04800415039062, 19.721399307250977  \n",
       "38976            Hawi       UPP  -155.86000061035156, 20.265300750732422  \n",
       "39286       Point Lay       PIZ                -163.0050049, 69.73290253  \n",
       "\n",
       "[821 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_code_clean = df_airport_large_medium_only.drop(columns=['CONTINENT', 'ISO_COUNTRY'])\n",
    "df_airport_code_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5bc88-0e8e-4834-97f9-f9fcd52378a0",
   "metadata": {},
   "source": [
    "<p>\n",
    "By assessing the data types, we determined that all data types are appropriate. No actions needed.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4efb71f6-9160-4055-918d-aee405f7adfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 858 entries, 6194 to 50008\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   TYPE          858 non-null    object \n",
      " 1   NAME          858 non-null    object \n",
      " 2   ELEVATION_FT  855 non-null    float64\n",
      " 3   CONTINENT     0 non-null      object \n",
      " 4   ISO_COUNTRY   858 non-null    object \n",
      " 5   MUNICIPALITY  855 non-null    object \n",
      " 6   IATA_CODE     821 non-null    object \n",
      " 7   COORDINATES   858 non-null    object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 60.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_airport_large_medium_only.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bc8b3-b613-4046-ab63-2b158a560217",
   "metadata": {},
   "source": [
    "#### <strong>3. Save cleaned data to CSV files (cleaned_Flight.csv, cleaned_Tickets.csv and cleaned_Airport_Codes.csv) for next steps;</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4bbac9e-2785-49de-9926-dbd661239940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after cleaning, let's output all csv files to the clean folder\n",
    "\n",
    "df_flights_cleaned.to_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_cleaned/cleaned_Flights.csv', index = False)\n",
    "df_tickets_cleaned.to_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_cleaned/cleaned_Tickets.csv', index = False)\n",
    "df_airport_code_clean.to_csv('/Users/yuchengliu/Desktop/c1 data challenge/data_cleaned/cleaned_Airport_Codes.csv', index = False)\n",
    "\n",
    "#end of data load, wrangling and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f049307-f9db-4fcd-a078-587851a11897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Raw Counts</th>\n",
       "      <th>Clean Counts</th>\n",
       "      <th>Remain%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLIGHTS</td>\n",
       "      <td>1915886</td>\n",
       "      <td>1858595</td>\n",
       "      <td>97.009686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TICKETS</td>\n",
       "      <td>1167285</td>\n",
       "      <td>706849</td>\n",
       "      <td>60.554963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIRPORT CODES</td>\n",
       "      <td>55369</td>\n",
       "      <td>858</td>\n",
       "      <td>1.549604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data  Raw Counts  Clean Counts    Remain%\n",
       "0        FLIGHTS     1915886       1858595  97.009686\n",
       "1        TICKETS     1167285        706849  60.554963\n",
       "2  AIRPORT CODES       55369           858   1.549604"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data loss percentage\n",
    "\n",
    "columns = ['Data', 'Raw Counts', 'Clean Counts', 'Remain%']\n",
    "data = [('FLIGHTS', len(df_flights),len(df_flights_cleaned), len(df_flights_cleaned)* 100 / len(df_flights)), \\\n",
    "        ('TICKETS', len(df_tickets), len(df_tickets_cleaned), len(df_tickets_cleaned)*100 / len(df_tickets)), \\\n",
    "        ('AIRPORT CODES', len(df_airport_codes), len(df_airport_code_clean), len(df_airport_code_clean) * 100 / len(df_airport_codes))]\n",
    "df_data_loss = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df_data_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
